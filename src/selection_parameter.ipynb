{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config_files(directory_path):\n",
    "    knob_list = glob.glob(os.path.join(directory_path, \"my_*.cnf\"))\n",
    "    cnt = 0\n",
    "    A_config = None\n",
    "\n",
    "    for xx in range(len(knob_list)):\n",
    "        path = os.path.join(directory_path, \"my_{}.cnf\".format(xx))\n",
    "        a_all = pd.read_csv(path, sep=\"=\", names=['Sample', 'value'], header=5)\n",
    "        a_all = a_all.set_index(\"Sample\").T\n",
    "        cur_all_df = a_all\n",
    "\n",
    "        if cnt == 0:\n",
    "            A_config = cur_all_df\n",
    "        else:\n",
    "            A_config = pd.concat([A_config, cur_all_df], axis=0)\n",
    "        cnt += 1\n",
    "\n",
    "    A_config = A_config.reset_index(drop=True)\n",
    "    \n",
    "    # 전처리: 문자열이나 비정상적인 값을 NaN으로 처리하고 나중에 채움\n",
    "    A_config.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    A_config = A_config.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    return A_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    scores = cross_val_score(model, X, y, cv=5) # 교차검증\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "# 모델의 평균 점수와, 표준편차를 반홤함 -> 모델의 성능 검증에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_dataset(directory_path, external_metrics_path):\n",
    "    # 설정 파일 로드\n",
    "    configs_df = load_config_files(directory_path)\n",
    "\n",
    "    # 외부 성능 메트릭 로드\n",
    "    external_metrics = pd.read_csv(external_metrics_path, index_col=0)\n",
    "\n",
    "    # 결측값 대체 (IterativeImputer 사용)\n",
    "    imputer = IterativeImputer(random_state=42)\n",
    "    configs_imputed = pd.DataFrame(imputer.fit_transform(configs_df), columns=configs_df.columns)\n",
    "    external_metrics_imputed = pd.DataFrame(imputer.fit_transform(external_metrics), columns=external_metrics.columns)\n",
    "\n",
    "    # 특징(X)와 타겟(y) 분리\n",
    "    X = configs_imputed\n",
    "    y = external_metrics_imputed[['tps', 'latency']]\n",
    "\n",
    "    # 각 타겟에 대해 별도로 Lasso 모델 훈련 및 중요도 계산\n",
    "    importance = pd.DataFrame()\n",
    "    for target in y.columns:\n",
    "        model = LassoCV(cv=5, random_state=42).fit(X, y[target])\n",
    "\n",
    "        # 모델 평가\n",
    "        mean_score, std_score = evaluate_model(model, X, y[target])\n",
    "        print(f'Model performance for {target}: Mean score = {mean_score}, Std dev = {std_score}')\n",
    "\n",
    "        target_importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            f'importance_{target}': np.abs(model.coef_)\n",
    "        })\n",
    "\n",
    "        if importance.empty:\n",
    "            importance = target_importance\n",
    "        else:\n",
    "            importance = pd.merge(importance, target_importance, on='feature')\n",
    "\n",
    "    # 각 타겟의 중요도를 합산하여 전체 중요도 계산\n",
    "    importance['importance'] = importance[[f'importance_{target}' for target in y.columns]].mean(axis=1)\n",
    "    \n",
    "    return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 워크로드를 처리하여 결과를 취합\n",
    "root_directory = '/Users/yoonji_kim/delab/tuning/mysql_dataset'\n",
    "\n",
    "workload_paths = {\n",
    "    'AA': {\n",
    "        'config_path': f'{root_directory}/ycsb_AA/configs',\n",
    "        'metrics_path': f'{root_directory}/ycsb_AA/results/external_metrics_AA.csv'\n",
    "    },\n",
    "    'BB': {\n",
    "        'config_path': f'{root_directory}/ycsb_BB/configs',\n",
    "        'metrics_path': f'{root_directory}/ycsb_BB/results/external_metrics_BB.csv'\n",
    "    },\n",
    "    'EE': {\n",
    "        'config_path': f'{root_directory}/ycsb_EE/configs',\n",
    "        'metrics_path': f'{root_directory}/ycsb_EE/results/external_metrics_EE.csv'\n",
    "    },\n",
    "    'FF': {\n",
    "        'config_path': f'{root_directory}/ycsb_FF/configs',\n",
    "        'metrics_path': f'{root_directory}/ycsb_FF/results/external_metrics_FF.csv'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for tps: Mean score = 0.29186278548145417, Std dev = 0.05075943650015996\n",
      "Model performance for latency: Mean score = 0.2848290481575623, Std dev = 0.04391697999627951\n",
      "Error processing workload BB: Input X contains infinity or a value too large for dtype('float64').\n",
      "Error processing workload EE: Input X contains infinity or a value too large for dtype('float64').\n",
      "Error processing workload FF: Input X contains infinity or a value too large for dtype('float64').\n"
     ]
    }
   ],
   "source": [
    "# 중요도를 합산할 데이터프레임 초기화\n",
    "total_importance = pd.DataFrame()\n",
    "\n",
    "# 각 워크로드에 대해 처리\n",
    "for workload, paths in workload_paths.items():\n",
    "    try:\n",
    "        importance = process_single_dataset(paths['config_path'], paths['metrics_path'])\n",
    "        \n",
    "        if total_importance.empty:\n",
    "            total_importance = importance\n",
    "        else:\n",
    "            total_importance = pd.merge(total_importance, importance, on='feature', how='outer')\n",
    "            total_importance['importance'] = total_importance.filter(like='importance_').sum(axis=1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing workload {workload}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 important knobs across all workloads:\n",
      "                               feature  importance_tps  importance_latency  \\\n",
      "119            range_alloc_block_size     2.924906e-05            0.112549   \n",
      "113            query_alloc_block_size     1.330935e-06            0.008539   \n",
      "126                  sort_buffer_size     6.367625e-07            0.006673   \n",
      "46               innodb_log_file_size     2.651263e-09            0.000597   \n",
      "114                 query_cache_limit     9.039792e-08            0.000431   \n",
      "133                    tmp_table_size     7.332440e-08            0.000363   \n",
      "85                    key_buffer_size     2.904449e-08            0.000359   \n",
      "40       innodb_ft_result_cache_limit     8.748058e-09            0.000271   \n",
      "116                  query_cache_size     9.950875e-09            0.000207   \n",
      "100               max_heap_table_size     9.855458e-08            0.000205   \n",
      "95              max_binlog_cache_size     5.996286e-08            0.000203   \n",
      "97         max_binlog_stmt_cache_size     5.596204e-08            0.000188   \n",
      "94                 max_allowed_packet     2.980373e-08            0.000148   \n",
      "21            innodb_buffer_pool_size     6.772800e-09            0.000132   \n",
      "45             innodb_log_buffer_size     0.000000e+00            0.000116   \n",
      "55   innodb_online_alter_log_max_size     3.696106e-08            0.000103   \n",
      "6             bulk_insert_buffer_size     4.031071e-08            0.000074   \n",
      "96                    max_binlog_size     2.011090e-08            0.000022   \n",
      "53           innodb_max_undo_log_size     2.149820e-09            0.000019   \n",
      "42         innodb_ft_total_cache_size     6.995137e-08            0.000000   \n",
      "93                    long_query_time     0.000000e+00            0.000000   \n",
      "98                  max_digest_length     0.000000e+00            0.000000   \n",
      "92          log_slow_admin_statements     0.000000e+00            0.000000   \n",
      "91      log_queries_not_using_indexes     0.000000e+00            0.000000   \n",
      "0                            back_log     0.000000e+00            0.000000   \n",
      "90    log_bin_trust_function_creators     0.000000e+00            0.000000   \n",
      "99                    max_error_count     0.000000e+00            0.000000   \n",
      "88           key_cache_division_limit     0.000000e+00            0.000000   \n",
      "87               key_cache_block_size     0.000000e+00            0.000000   \n",
      "86            key_cache_age_threshold     0.000000e+00            0.000000   \n",
      "\n",
      "       importance  \n",
      "119  5.628916e-02  \n",
      "113  4.270158e-03  \n",
      "126  3.336793e-03  \n",
      "46   2.987305e-04  \n",
      "114  2.156336e-04  \n",
      "133  1.813355e-04  \n",
      "85   1.794991e-04  \n",
      "40   1.356314e-04  \n",
      "116  1.036389e-04  \n",
      "100  1.024885e-04  \n",
      "95   1.016186e-04  \n",
      "97   9.383399e-05  \n",
      "94   7.382640e-05  \n",
      "21   6.601062e-05  \n",
      "45   5.787178e-05  \n",
      "55   5.154346e-05  \n",
      "6    3.693958e-05  \n",
      "96   1.076605e-05  \n",
      "53   9.538730e-06  \n",
      "42   3.497568e-08  \n",
      "93   0.000000e+00  \n",
      "98   0.000000e+00  \n",
      "92   0.000000e+00  \n",
      "91   0.000000e+00  \n",
      "0    0.000000e+00  \n",
      "90   0.000000e+00  \n",
      "99   0.000000e+00  \n",
      "88   0.000000e+00  \n",
      "87   0.000000e+00  \n",
      "86   0.000000e+00  \n",
      "Top 30 knobs have been saved to top_30_knobs.csv\n"
     ]
    }
   ],
   "source": [
    "n = 30  # 상위 30개의 Knob 추출\n",
    "final_top_n_knobs = total_importance.sort_values(by='importance', ascending=False).head(n)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Top 30 important knobs across all workloads:\")\n",
    "print(final_top_n_knobs)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "output_file = '../csv/top_30_knobs.csv'\n",
    "final_top_n_knobs.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Top 30 knobs have been saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
